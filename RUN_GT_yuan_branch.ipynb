{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0b6f882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "Done, take 10.0 min 30.51249098777771 sec\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import vgg #Last layer self.orientation=4 self.confidence=4\n",
    "from torch_lib.Model import *\n",
    "from torch_lib.ClassAverages import *\n",
    "from torchvision import transforms\n",
    "import os, glob, cv2\n",
    "from library.ron_utils import *\n",
    "\n",
    "def class2angle(bin_class,residual):\n",
    "    # angle_per_class=2*torch.pi/float(12)\n",
    "    angle_per_class=2*np.pi/float(4)\n",
    "    angle=float(angle_per_class*bin_class)\n",
    "    angle=angle+residual\n",
    "    # print(angle)\n",
    "    return angle\n",
    "\n",
    "def get_calibration_cam_to_image(cab_f):\n",
    "    for line in open(cab_f):\n",
    "        if 'P2:' in line:\n",
    "            cam_to_img = line.strip().split(' ')\n",
    "            cam_to_img = np.asarray([float(number) for number in cam_to_img[1:]])\n",
    "            cam_to_img = np.reshape(cam_to_img, (3, 4))\n",
    "            return cam_to_img\n",
    "\n",
    "\n",
    "#def Run_GT_pred_labels(weights_path, pred_label_root):\n",
    "weights_path = 'weights/BL_4bin_epoch_20.pkl'\n",
    "pred_label_root = './BL_class2angle'\n",
    "os.makedirs(pred_label_root, exist_ok=True)\n",
    "my_vgg = vgg.vgg19_bn(pretrained=True)\n",
    "# dim\n",
    "#my_vgg.features[0] = nn.Conv2d(4, 64, (3,3), (1,1), (1,1))\n",
    "model = Model(features=my_vgg.features).cuda()\n",
    "\n",
    "checkpoint = torch.load(weights_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "# for img processing\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "process = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "# Kitti image_2 dir / label_2 dir\n",
    "img_root = \"./Kitti/training/image_2\"\n",
    "label_root = \"./Kitti/training/label_2\"\n",
    "calib_root = \"./Kitti/training/calib\"\n",
    "extra_label_root = \"./Kitti/training/extra_label\"\n",
    "\n",
    "images = glob.glob(os.path.join(img_root, '*.png'), recursive=True)\n",
    "labels = glob.glob(os.path.join(label_root, '*.txt'), recursive=True)\n",
    "calibs = glob.glob(os.path.join(calib_root, '*.txt'), recursive=True)\n",
    "extra = glob.glob(os.path.join(extra_label_root, '*.txt'), recursive=True)\n",
    "\n",
    "# dim averages\n",
    "averages_all = ClassAverages()\n",
    "start = time.time()\n",
    "for i in range(len(images)):\n",
    "    img = cv2.imread(images[i])\n",
    "    cam_to_img = get_calibration_cam_to_image(calibs[i])\n",
    "\n",
    "    CLASSes = list()\n",
    "    BOX2Ds = list()\n",
    "    CROPs_tensor = list()\n",
    "    Alphas = list()\n",
    "    THETAs = list()\n",
    "    extra_labels = open(extra[i]).read().splitlines()\n",
    "\n",
    "\n",
    "    with open(labels[i]) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for idx, line in enumerate(lines):\n",
    "            elements = line[:-1].split()\n",
    "            if elements[0] == 'DontCare':\n",
    "                continue\n",
    "            for j in range(1, len(elements)):\n",
    "                elements[j] = float(elements[j])\n",
    "\n",
    "            CLASSes.append(elements[0])\n",
    "            top_left = (int(round(elements[4])), int(round(elements[5])))\n",
    "            btm_right = (int(round(elements[6])), int(round(elements[7])))\n",
    "            box = [top_left, btm_right]\n",
    "            BOX2Ds.append(box)\n",
    "            #cv2 is(H,W,3)\n",
    "            crop = img[top_left[1]:btm_right[1]+1, top_left[0]:btm_right[0]+1] \n",
    "            crop = cv2.resize(src = crop, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "            crop = process(crop)\n",
    "            # Use calc function if cam_to_img changes to \"camera_cal/calib_cam_to_cam.txt\"\n",
    "            theta_ray = float(extra_labels[idx].split()[5])\n",
    "            THETAs.append(theta_ray)\n",
    "            CROPs_tensor.append(crop)\n",
    "            #4dim\n",
    "            #cond = torch.tensor(theta_ray).expand(1, crop.shape[1], crop.shape[2])\n",
    "            #img_cond = torch.concat((crop, cond), dim=0) # 3+1, 224, 224 + grouploss看看\n",
    "            #CROPs_tensor.append(img_cond)\n",
    "            \n",
    "        # put together as a batch\n",
    "        # model regress part\n",
    "        input_ = torch.stack(CROPs_tensor).cuda()\n",
    "\n",
    "        [ORIENTs, CONFs, delta_DIMs] = model(input_)\n",
    "        \n",
    "        cls_argmax = torch.max(CONFs, dim=1)[1]\n",
    "        #print(cls_argmax)\n",
    "        resdiual_orient = ORIENTs[torch.arange(len(ORIENTs)), cls_argmax]\n",
    "        for argmax, resdiual in zip(cls_argmax, resdiual_orient):\n",
    "            alpha=class2angle(argmax,resdiual)\n",
    "            if alpha >np.pi:\n",
    "                alpha-=(2*np.pi)\n",
    "            Alphas.append(alpha)\n",
    "        \n",
    "\n",
    "    #write pred_label.txt \n",
    "    with open(labels[i].replace(label_root, pred_label_root),'w') as new_f:\n",
    "        pred_labels = ''\n",
    "        for class_, delta, alpha, theta, box_2d in zip(CLASSes, delta_DIMs, Alphas, THETAs, BOX2Ds):\n",
    "            delta = delta.cpu().data.numpy() #torch->numpy\n",
    "            alpha = alpha.cpu().data.numpy() #torch->numpy\n",
    "            dim = delta + averages_all.get_item(class_)\n",
    "            rotation_y = alpha + theta\n",
    "            loc, _ = calc_location(dim, cam_to_img, box_2d, alpha, theta)\n",
    "\n",
    "            pred_labels += '{CLASS} 0.0 0 {A:.2f} {left} {top} {right} {btm} {H:.2f} {W:.2f} {L:.2f} {X:.2f} {Y:.2f} {Z:.2f} {Ry:.2f}\\n'.format(\n",
    "                CLASS=class_, A=alpha, left=box_2d[0][0], top=box_2d[0][1], right=box_2d[1][0], btm=box_2d[1][1],\n",
    "                H=dim[0], W=dim[1], L=dim[2], X=loc[0], Y=loc[1], Z=loc[2], Ry=rotation_y)\n",
    "        #print(pred_labels)\n",
    "        new_f.writelines(pred_labels)\n",
    "    #print(pred_labels)\n",
    "    if i%500==0:\n",
    "        print(i)\n",
    "print('Done, take {} min {} sec'.format((time.time()-start)//60, (time.time()-start)%60))# around 10min"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
