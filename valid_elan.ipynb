{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg\n",
    "from torch_lib.Model_heading_bin import *\n",
    "from torch_lib.ClassAverages import *\n",
    "from torchvision import transforms\n",
    "import os, glob, cv2\n",
    "from library.ron_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_regressed_3d_bbox(img, cam_to_img, box_2d, dimensions, alpha, theta_ray, detectionid):\n",
    "\n",
    "    # the math! returns X, the corners used for constraint\n",
    "    location, X = calc_location(dimensions, cam_to_img, box_2d, alpha, theta_ray)\n",
    "\n",
    "    orient = alpha + theta_ray\n",
    "\n",
    "    #plot_2d_box(img, box_2d, detectionid)\n",
    "    plot_3d_box(img, cam_to_img, orient, dimensions, location) # 3d boxes\n",
    "\n",
    "    return location, orient\n",
    "\n",
    "#REG PNG TO VIDEO\n",
    "import cv2, os, glob\n",
    "def make_video(folder, img_paths, fps=15):\n",
    "    reg_folder = os.path.join(folder, 'reg_images')\n",
    "    video_name = os.path.join(folder, 'eval.avi')\n",
    "    image0 = os.path.join(sub_folder, img_paths[0])\n",
    "    frame = cv2.imread(image0)\n",
    "    height, width, layers = frame.shape\n",
    "    video = cv2.VideoWriter(video_name, 0, fps=fps, frameSize=(width,height))\n",
    "    for i in range(len(img_paths)):\n",
    "        path = os.path.join(folder, img_paths[i].replace('images', 'reg_images'))\n",
    "        video.write(cv2.imread(path))\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'weights/DA_B4_N1_50.pkl'\n",
    "device = torch.device('cuda') # 選gpu的index\n",
    "checkpoint = torch.load(weights_path, map_location=device) #if training on 2 GPU, mapping on the same device\n",
    "normalize_type = checkpoint['normal']\n",
    "bin_num = checkpoint['bin']\n",
    "angle_per_class = 2*np.pi/float(bin_num)\n",
    "\n",
    "my_vgg = vgg.vgg19_bn(weights='DEFAULT').to(device)\n",
    "model = Model(features=my_vgg.features, bins=bin_num).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# for img processing\n",
    "if normalize_type == 0:\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "if normalize_type == 1:\n",
    "    normalize = transforms.Normalize(mean=[0.596, 0.612, 0.587], std=[0.256, 0.254, 0.257])\n",
    "process = transforms.Compose([transforms.ToTensor(), \n",
    "                              transforms.Resize([224,224], transforms.InterpolationMode.BICUBIC), \n",
    "                              normalize])\n",
    "\n",
    "ELAN_averages = ClassAverages(average_file='all_ELAN_class_averages.txt')\n",
    "cam_to_img = np.array([\n",
    "        [1.418667e+03, 0.000e+00, 6.4e+02, 0],\n",
    "        [0.000e+00, 1.418867e+03, 3.6e+02, 0],\n",
    "        [0.000e+00, 000e+00, 1.0e+00, 0] ])\n",
    "class_dict = {8:'truck', 9:'car', 10:'motor', 11:'bike'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval all folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE IVAvalid_for_NCTU/day\\c32b95371b6b-SOS20230209-091818-824\n",
      "ALL FINISHED\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "valid_folder = 'IVAvalid_for_NCTU'\n",
    "for time in ['day', 'night']:\n",
    "    folder = f'{valid_folder}/{time}'\n",
    "    for sub_f in os.listdir(folder):\n",
    "        sub_folder = os.path.join(folder, sub_f)\n",
    "        with open(f'{sub_folder}/TEST_images.json') as f:\n",
    "            img_paths = json.load(f)\n",
    "        label_json = f'{sub_folder}/TEST_objects.json'\n",
    "        with open(label_json) as f:\n",
    "            label_dicts = json.load(f)\n",
    "            \n",
    "        os.makedirs(os.path.join(sub_folder,'reg_images'), exist_ok=True)\n",
    "        model.eval()\n",
    "        for i in range(len(img_paths)):\n",
    "            path = os.path.join(sub_folder, img_paths[i])\n",
    "            save_path = path.replace('images', 'reg_images')\n",
    "            img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            label_dict = label_dicts[i]\n",
    "            for j in range(len(label_dict['labels'])):\n",
    "                difficulty = label_dict['difficulties'][j] # 1 is hard to distinguish\n",
    "                if difficulty == 0:\n",
    "                    color = (255, 0, 0)\n",
    "                    line_width = 2\n",
    "                else:\n",
    "                    color = (0, 0, 255)\n",
    "                    line_width = 1\n",
    "                class_ = class_dict[label_dict['labels'][j]] # 5:行人,6:機車騎士,7:腳踏車騎士,8:大車,9:小車,10:機車,11:腳踏車\n",
    "                object_id = label_dict['id'][j] # for tracking\n",
    "                box_2d = label_dict['boxes'][j]\n",
    "                box_2d = [[box_2d[0], box_2d[1]], [box_2d[2],box_2d[3]]]\n",
    "                left_top = box_2d[0]\n",
    "                right_btm = box_2d[1]\n",
    "\n",
    "                crop = img[left_top[1]:right_btm[1]+1, left_top[0]:right_btm[0]+1] \n",
    "                crop = process(crop) \n",
    "                crop = torch.stack([crop]).to(device)\n",
    "\n",
    "                [RESIDUALs, BIN_CONFs, delta_DIMs] = model(crop)\n",
    "                bin_argmax = torch.max(BIN_CONFs, dim=1)[1]\n",
    "                orient_residual = RESIDUALs[torch.arange(len(RESIDUALs)), bin_argmax] \n",
    "                Alphas = angle_per_class*bin_argmax + orient_residual #mapping bin_class and residual to get alpha\n",
    "                alpha_Elan = float(Alphas[0].data)\n",
    "                alpha_Elan = angle_correction(alpha_Elan)\n",
    "                dim_Elan = delta_DIMs.cpu().data.numpy()[0, :]\n",
    "                dim_Elan += ELAN_averages.get_item(class_)\n",
    "                dim_Elan = np.round(dim_Elan, 2)\n",
    "                theta_ray = calc_theta_ray(img.shape[1], box_2d, cam_to_img)\n",
    "                loc, ry = plot_regressed_3d_bbox(img, cam_to_img, box_2d, dim_Elan, alpha_Elan, theta_ray, j)\n",
    "                #print(j, difficulty)\n",
    "                #print(np.round(dim_Elan, 2))\n",
    "\n",
    "                #print(np.round(loc, 2), ry)\n",
    "                #cv2.rectangle(img, left_top, right_btm, color, line_width)\n",
    "            plt.imsave(save_path, img)\n",
    "            #plt.show()\n",
    "        print(f'DONE {sub_folder}')\n",
    "        make_video(sub_folder, img_paths, fps=15)\n",
    "        break\n",
    "    break\n",
    "print('ALL FINISHED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make video only (given folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os, glob\n",
    "valid_folder = 'IVAvalid_for_NCTU'\n",
    "for time in ['day', 'night']:\n",
    "    folder = f'{valid_folder}/{time}'\n",
    "    for sub_f in os.listdir(folder):\n",
    "        sub_folder = os.path.join(folder, sub_f)\n",
    "        with open(f'{sub_folder}/TEST_images.json') as f:\n",
    "            img_paths = json.load(f)\n",
    "        make_video(sub_folder, img_paths)\n",
    "        print(f'Done {sub_folder}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVAL 1 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "folder = 'IVAvalid_for_NCTU/day/c32b95371b6b-SOS20230226-143946-2887'\n",
    "img_json = '/TEST_images.json'\n",
    "with open(f'{folder}/TEST_images.json') as f:\n",
    "    img_paths = json.load(f)\n",
    "label_json = f'{folder}/TEST_objects.json'\n",
    "with open(label_json) as f:\n",
    "    label_dicts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'weights/DA_B4_N1_50.pkl'\n",
    "device = torch.device('cpu') # 選gpu的index\n",
    "checkpoint = torch.load(weights_path, map_location=device) #if training on 2 GPU, mapping on the same device\n",
    "normalize_type = checkpoint['normal']\n",
    "bin_num = checkpoint['bin']\n",
    "angle_per_class = 2*np.pi/float(bin_num)\n",
    "\n",
    "my_vgg = vgg.vgg19_bn(weights='DEFAULT').to(device)\n",
    "model = Model(features=my_vgg.features, bins=bin_num).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# for img processing\n",
    "if normalize_type == 0:\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "if normalize_type == 1:\n",
    "    normalize = transforms.Normalize(mean=[0.596, 0.612, 0.587], std=[0.256, 0.254, 0.257])\n",
    "process = transforms.Compose([transforms.ToTensor(), \n",
    "                              transforms.Resize([224,224], transforms.InterpolationMode.BICUBIC), \n",
    "                              normalize])\n",
    "\n",
    "ELAN_averages = ClassAverages(average_file='all_ELAN_class_averages.txt')\n",
    "cam_to_img = np.array([\n",
    "        [1.418667e+03, 0.000e+00, 6.4e+02, 0],\n",
    "        [0.000e+00, 1.418867e+03, 3.6e+02, 0],\n",
    "        [0.000e+00, 000e+00, 1.0e+00, 0] ])\n",
    "class_dict = {8:'truck', 9:'car', 10:'motor', 11:'bike'}\n",
    "# EVAL\n",
    "model.eval()\n",
    "\n",
    "os.makedirs(os.path.join(folder,'reg_images'), exist_ok=True)\n",
    "for i in range(len(img_paths)):\n",
    "    path = os.path.join(folder, img_paths[i])\n",
    "    save_path = path.replace('images', 'reg_images')\n",
    "    img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    label_dict = label_dicts[i]\n",
    "    for j in range(len(label_dict['labels'])):\n",
    "        difficulty = label_dict['difficulties'][j] # 1 is hard to distinguish\n",
    "        if difficulty == 0:\n",
    "            color = (255, 0, 0)\n",
    "            line_width = 2\n",
    "        else:\n",
    "            color = (0, 0, 255)\n",
    "            line_width = 1\n",
    "        class_ = class_dict[label_dict['labels'][j]] # 5:行人,6:機車騎士,7:腳踏車騎士,8:大車,9:小車,10:機車,11:腳踏車\n",
    "        object_id = label_dict['id'][j] # for tracking\n",
    "        box_2d = label_dict['boxes'][j]\n",
    "        box_2d = [[box_2d[0], box_2d[1]], [box_2d[2],box_2d[3]]]\n",
    "        left_top = box_2d[0]\n",
    "        right_btm = box_2d[1]\n",
    "        \n",
    "        crop = img[left_top[1]:right_btm[1]+1, left_top[0]:right_btm[0]+1] \n",
    "        crop = process(crop) \n",
    "        crop = torch.stack([crop]).to(device)\n",
    "        \n",
    "        [RESIDUALs, BIN_CONFs, delta_DIMs] = model(crop)\n",
    "        bin_argmax = torch.max(BIN_CONFs, dim=1)[1]\n",
    "        orient_residual = RESIDUALs[torch.arange(len(RESIDUALs)), bin_argmax] \n",
    "        Alphas = angle_per_class*bin_argmax + orient_residual #mapping bin_class and residual to get alpha\n",
    "        alpha_Elan = float(Alphas[0].data)\n",
    "        alpha_Elan = angle_correction(alpha_Elan)\n",
    "        dim_Elan = delta_DIMs.cpu().data.numpy()[0, :]\n",
    "        dim_Elan += ELAN_averages.get_item(class_)\n",
    "        dim_Elan = np.round(dim_Elan, 2)\n",
    "        theta_ray = calc_theta_ray(img.shape[1], box_2d, cam_to_img)\n",
    "        loc, ry = plot_regressed_3d_bbox(img, cam_to_img, box_2d, dim_Elan, alpha_Elan, theta_ray, j)\n",
    "        #print(j, difficulty)\n",
    "        #print(np.round(dim_Elan, 2))\n",
    "        \n",
    "        #print(np.round(loc, 2), ry)\n",
    "        #cv2.rectangle(img, left_top, right_btm, color, line_width)\n",
    "    plt.imsave(save_path, img)\n",
    "    #plt.show()\n",
    "print(f'DONE {folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
